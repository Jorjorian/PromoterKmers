{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:24:57.408182600Z",
     "start_time": "2024-11-17T22:24:56.810689300Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import parallel_backend"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# load in the data \n",
    "\n",
    "promoters = pd.read_csv('Data/promoter.csv')\n",
    "promoters.columns = ['Sequence']\n",
    "non_promoters = pd.read_csv('Data/non_promoter.csv')\n",
    "non_promoters.columns = ['Sequence']\n",
    "label_vector = np.ones(promoters.shape[0]).tolist() + np.zeros(non_promoters.shape[0]).tolist()\n",
    "combined_data = pd.concat([promoters, non_promoters], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:24:58.637683700Z",
     "start_time": "2024-11-17T22:24:58.499930100Z"
    }
   },
   "id": "a953f9a9ae315df3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# train test validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    combined_data, label_vector, test_size=0.2, stratify=label_vector, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.125, stratify=y_train_val, random_state=42\n",
    ")  # 0.125 because 0.125 * 80% = 10%\n",
    "\n",
    "# Check the sizes\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Validation size: {len(X_val)}\")\n",
    "print(f\"Test size: {len(X_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:25:24.364883300Z",
     "start_time": "2024-11-17T22:25:24.319140400Z"
    }
   },
   "id": "a9e3ff51e47e319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 42000\n",
      "Validation size: 6000\n",
      "Test size: 12000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "y_train = np.array(y_train)\n",
    "print(X_train)\n",
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:25:27.496122600Z",
     "start_time": "2024-11-17T22:25:27.480121700Z"
    }
   },
   "id": "5183ab758a51357e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Sequence\n",
      "8648   TGGCAAGGGGCCGTGGAGCCTGTAAGACTATCCCCCCAGCCACCCA...\n",
      "27325  AATATGTAGGCAGTTTTCTTTGCTTTGACATGGAAGCAGTTTTAAC...\n",
      "24871  TCCGCAGCTGGTGTCCTTCAACAAAAGTAATCACCTCTCTCCCCGG...\n",
      "16509  TTCCCTGTTCTTCACAATCTGTGAGCACTGTAATGTTACACTTCAA...\n",
      "12014  ACTAGGTCCTTCTTCCCCATGTTTTATACAGACGGACCAGAAGCCA...\n",
      "...                                                  ...\n",
      "17648  AATGAATATGTTGGAAATTATATGCAAATTGGCTTCCGTTGGTGTT...\n",
      "28299  CACAGGCTTACAGGTACAGTCAGCGGACCCAGCCTGGGCTGGATCT...\n",
      "14293  CCATCTCTGAGATATGTGGTCTTGACCTCCCAGCATGAAGTGTGCA...\n",
      "27224  TCCGCTGAACTATTGCCCCCGACGGGCTTTGTTCGAAGACAATCAC...\n",
      "14640  AGTGACATCGAGATGGGCTCTTTTCACCCCCCTCCCCCACTGCTCT...\n",
      "\n",
      "[42000 rows x 1 columns]\n",
      "[1. 0. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class KmerVectorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to vectorize k-mers for different K values.\n",
    "    \"\"\"\n",
    "    def __init__(self, K=3):\n",
    "        self.K = K\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer = CountVectorizer(analyzer='char', ngram_range=(self.K, self.K))\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "\n",
    "def evaluate_model(best_model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model on the reserved test set and generate metrics including ROC curves.\n",
    "\n",
    "    Parameters:\n",
    "    - best_model: The trained model to evaluate.\n",
    "    - X_test: Test data (features).\n",
    "    - y_test: Test labels.\n",
    "    - model_name: Name of the model for saving results.\n",
    "\n",
    "    Returns:\n",
    "    - metrics: Dictionary of evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(f\"Evaluating {model_name} on test data...\")\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    # Generate ROC curve\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['roc_auc'] = roc_auc\n",
    "\n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "        plt.title(f\"ROC Curve for {model_name}\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"{model_name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "        print(f\"ROC curve saved as '{model_name}_roc_curve.png'\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def gridsearch_with_logging(X_train, y_train, model, param_grid, model_name, cv=5, scoring='accuracy', max_cpu_fraction=0.7):\n",
    "    \"\"\"\n",
    "    Perform grid search with cross-validation, tracking progress and logging results, while limiting resource usage.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training data (features).\n",
    "    - y_train: Training labels.\n",
    "    - model: sklearn model.\n",
    "    - param_grid: Parameter grid for grid search.\n",
    "    - model_name: Name of the model for saving/loading files.\n",
    "    - cv: Number of cross-validation folds.\n",
    "    - scoring: Scoring metric.\n",
    "    - max_cpu_fraction: Fraction of available CPU resources to use.\n",
    "\n",
    "    Returns:\n",
    "    - best_model: Trained pipeline with the best parameters.\n",
    "    - best_params: Best parameter set.\n",
    "    - best_score: Best cross-validation score.\n",
    "    \"\"\"\n",
    "    # Check if the model is already trained\n",
    "    model_file = f'best_{model_name}_model.pkl'\n",
    "    log_file = f'{model_name}_gridsearch_log.csv'\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print(f\"Model '{model_file}' already exists. Loading the model...\")\n",
    "        best_model = joblib.load(model_file)\n",
    "        return best_model, None, None\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('kmer', KmerVectorizer()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Set up GridSearchCV\n",
    "    total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,# Will be controlled by `parallel_backend`\n",
    "        verbose= 4\n",
    "    )\n",
    "\n",
    "    # Custom callback for progress tracking\n",
    "    current_combination = 0\n",
    "\n",
    "    # Start grid search with resource constraints\n",
    "    print(f\"Starting grid search for {model_name} with up to {max_cpu_fraction * 100:.0f}% CPU usage...\")\n",
    "\n",
    "    with parallel_backend('loky', n_jobs=int(max_cpu_fraction * os.cpu_count())):\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Save log\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    results.to_csv(log_file, index=False)\n",
    "\n",
    "    # Get the best model and save it\n",
    "    best_model = grid_search.best_estimator_\n",
    "    joblib.dump(best_model, model_file)\n",
    "    print(f\"Best model saved as '{model_file}'\")\n",
    "\n",
    "    return best_model, grid_search.best_params_, grid_search.best_score_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:40:40.654263300Z",
     "start_time": "2024-11-17T22:40:40.637737200Z"
    }
   },
   "id": "4951855922987af2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "raw",
   "source": [
    "Testing Truncated Singular Value Decomposition on different K values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "795fb4e565419856"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 10))\n",
    "for i, K in enumerate([4, 6, 8, 10, 12, 14]):\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('kmer', KmerVectorizer(K=K)),\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('pca', TruncatedSVD(n_components=2))\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data\n",
    "    X_pca = pipeline.fit_transform(X_train['Sequence'].values)\n",
    "\n",
    "    # Plot the data\n",
    "    j = i // 3\n",
    "    i = i % 3\n",
    "    print(i, j)\n",
    "    ax[i, j].scatter(X_pca[y_train == 0, 0], X_pca[y_train == 0, 1], label='Non-Promoter')\n",
    "    ax[i, j].scatter(X_pca[y_train == 1, 0], X_pca[y_train == 1, 1], label='Promoter')\n",
    "    ax[i, j].set_title(f\"K = {K}\")\n",
    "    ax[i, j].legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-17T22:24:31.287755500Z"
    }
   },
   "id": "49cb3516421c6a23"
  },
  {
   "cell_type": "code",
   "source": [
    "# training Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(f\"X_train shape: {len(X_train)}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_param_grid = {\n",
    "    'kmer__K': [4, 6, 8, 10],\n",
    "    'model__alpha': [0.1, 0.5, 1.0],\n",
    "}\n",
    "best_nb_model, best_nb_params, best_nb_score = gridsearch_with_logging(\n",
    "    X_train['Sequence'].values, y_train, nb_model, nb_param_grid, 'naive_bayes'\n",
    ")\n",
    "# displaying the best parameters and score\n",
    "print(\"Best Parameters:\", best_nb_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:40:45.377171500Z",
     "start_time": "2024-11-17T22:40:45.358146800Z"
    }
   },
   "id": "2c4928273f0dadcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: 42000\n",
      "y_train shape: 42000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_267348\\2988267993.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"X_train shape: {len(X_train)}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"y_train shape: {len(y_train)}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mX_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Sequence'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mnb_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMultinomialNB\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m nb_param_grid = {\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating naive_bayes on test data...\n",
      "ROC curve saved as 'naive_bayes_roc_curve.png'\n",
      "{'accuracy': 0.83925, 'precision': 0.8749309265058022, 'recall': 0.7916666666666666, 'f1': 0.8312188292939015, 'roc_auc': 0.896454875}\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "print(best_nb_params)\n",
    "nb_metrics = evaluate_model(best_nb_model, X_test['Sequence'].values, y_test, 'naive_bayes')\n",
    "print(nb_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:46:06.352198600Z",
     "start_time": "2024-11-17T22:46:02.034864200Z"
    }
   },
   "id": "759b5481e3162699"
  },
  {
   "cell_type": "code",
   "source": [
    "# training Random Forest model\n",
    "# Define the Random Forest model and parameter grid\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'kmer__K': [4, 6, 8, 10,],  # Different k-mer sizes\n",
    "    'model__n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'model__max_depth': [10, 20, 50, 100],  # Maximum depth of the trees\n",
    "    'model__min_samples_split': [2],  # Minimum samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Perform grid search with logging\n",
    "best_rf_model, best_rf_params, best_rf_score = gridsearch_with_logging(\n",
    "    X_train=X_train['Sequence'].values,\n",
    "    y_train=y_train,\n",
    "    model=model,\n",
    "    param_grid=param_grid,\n",
    "    model_name='random_forest',\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:42:03.286022500Z",
     "start_time": "2024-11-17T22:40:53.689381400Z"
    }
   },
   "id": "85a3696b620e792e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for random_forest with up to 70% CPU usage...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_267348\\2135315450.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;31m# Perform grid search with logging\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m best_model, best_params, best_score = gridsearch_with_logging(\n\u001B[0m\u001B[0;32m     13\u001B[0m     \u001B[0mX_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0my_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_267348\\1651303729.py\u001B[0m in \u001B[0;36mgridsearch_with_logging\u001B[1;34m(X_train, y_train, model, param_grid, model_name, cv, scoring, max_cpu_fraction)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'loky'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_cpu_fraction\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 123\u001B[1;33m         \u001B[0mgrid_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    124\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    125\u001B[0m         \u001B[1;31m# Save log\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1390\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1391\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1392\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1393\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    836\u001B[0m                     )\n\u001B[0;32m    837\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 838\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1054\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    933\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 935\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    936\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    439\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 441\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    442\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    443\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", best_rf_params)\n",
    "rf_metrics = evaluate_model(best_rf_model, X_test['Sequence'].values, y_test, 'random_forest')\n",
    "print(rf_metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ca97054a93e6fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training SVM model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(probability=True)\n",
    "param_grid = {\n",
    "    'kmer__K': [4, 6, 8, 10, 12, 14, 16],\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__gamma': ['scale', 'auto'],\n",
    "    'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "best_svm_model, best_svm_params, best_svm_score = gridsearch_with_logging(\n",
    "    X_train=X_train['Sequence'].values,\n",
    "    y_train=y_train,\n",
    "    model=model,\n",
    "    param_grid=param_grid,\n",
    "    model_name='svm',\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86eade2ecf8079b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", best_params)\n",
    "svm_metrics = evaluate_model(best_svm_model, X_test['Sequence'].values, y_test, 'svm')\n",
    "print(svm_metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d28e528166fd78f"
  },
  {
   "cell_type": "raw",
   "source": [
    "Part 2: setting up Neural Network model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b0fee9851397dc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acb4e0e27019b6cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
